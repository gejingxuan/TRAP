{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a tutorial to use the trained TRAP model weights to predict whether CDR3beta binds to a specified epitope. Before running the notebook, the user needs to install the environment. For installation of the environment, refer to the requirements.txt file or trap.tar.gz in https://zenodo.org/records/15062393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1. Candidate CDR3beta generation for virtual screening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -se (/home/gejingxuan/anaconda3/envs/trap/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequence generation... \n",
      "Completed generating all 20 sequences in 0.00 seconds.\n",
      "Found 20 valid CDR3beta sequences\n",
      "First 5 sequences: ['SARRRARTEAF', 'ASSGLLAKNIQY', 'AQRSVSGANEKLF', 'ASSLAVLSHNSPLH', 'ASSLDSYVKNTQY']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.system('olga-generate_sequences --humanTRB -o screen.tsv -n 20')\n",
    "df = pd.read_csv('screen.tsv', sep='\\t', header=None)\n",
    "candidate_cdr = df.iloc[:,1].str.match('^C.*F$')\n",
    "candidate_cdr = df[candidate_cdr].iloc[:,1].str[1:-1].tolist()\n",
    "\n",
    "print(f'Found {len(candidate_cdr)} valid CDR3beta sequences')\n",
    "print('First 5 sequences:', candidate_cdr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2. Generation of CDR3 beta embedding features. (only keep the CDR3 betas which length <= 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/gejingxuan/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TRAP.cdr_gen import cdr_align\n",
    "import pickle\n",
    "\n",
    "b_max = 18\n",
    "device = 0\n",
    "dev = torch.device(f'cuda:{device}' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs('./cdr_feat', exist_ok=True)\n",
    "\n",
    "# esm\n",
    "esm_model, esm_alphabet = torch.hub.load(\"facebookresearch/esm:main\", \n",
    "                                            \"esm2_t33_650M_UR50D\")\n",
    "esm_batch_converter = esm_alphabet.get_batch_converter()\n",
    "esm_model = esm_model.to(dev)\n",
    "esm_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b_seq in candidate_cdr:\n",
    "        dic = cdr_align(esm_model, esm_batch_converter, dev,\n",
    "                                            b_seq,\n",
    "                                            use_cpu=True, \n",
    "                                            b_max=b_max)\n",
    "        with open('./cdr_feat/' + b_seq, 'wb') as f:\n",
    "            pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3.Generation of epitope embedding features. (eg.HLA-A*02:01 GLCTLVAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/gejingxuan/.cache/torch/hub/facebookresearch_esm_main\n",
      "@> 62 atoms and 1 coordinate set(s) were parsed in 0.00s.\n",
      "@> 2947 atoms and 1 coordinate set(s) were parsed in 0.03s.\n"
     ]
    }
   ],
   "source": [
    "from TRAP.pmhc_gen import epi_feature_esm\n",
    "dis_threshold1 = 5\n",
    "dis_threshold2 = 8\n",
    "dis_threshold3 = 15\n",
    "epi_max = 12\n",
    "epi = 'A_02_01_GLCTLVAML'\n",
    "struc_path = '/home/gejingxuan/TCR/data/our_data/pmhc_struc'\n",
    "file_path = './epi_feat'\n",
    "\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "device = 0\n",
    "# dev = torch.device(f'cuda:{device}' if torch.cuda.is_available() else \"cpu\")\n",
    "dev = torch.device(\"cpu\")\n",
    "esm_model, esm_alphabet = torch.hub.load(\"facebookresearch/esm:main\", \n",
    "                                            \"esm2_t33_650M_UR50D\")\n",
    "esm_batch_converter = esm_alphabet.get_batch_converter()\n",
    "esm_model = esm_model.to(dev)\n",
    "esm_model.eval()\n",
    "with torch.no_grad():\n",
    "    system_path = struc_path+'/'+epi\n",
    "    epi_feat = epi_feature_esm(system_path, dis_threshold1, dis_threshold2, dis_threshold3, epi_max,\n",
    "                               esm_model, esm_batch_converter, dev)\n",
    "    with open(file_path+'/'+epi,'wb') as fo:\n",
    "        pickle.dump(epi_feat, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3.5. Save candidate CDR3 and epitope information to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created with shape: (20, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'CDR3': candidate_cdr,\n",
    "    'pmhc': [epi] * len(candidate_cdr),\n",
    "    'labels': [0] * len(candidate_cdr),\n",
    "    'idx': range(len(candidate_cdr))\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('test.csv', index=False)\n",
    "print('CSV file created with shape:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously saved dgl graphs and corresponding data...\n"
     ]
    }
   ],
   "source": [
    "from TRAP.train import TrapDataset, DataLoaderX, collate_fn_v2, TransTRAP\n",
    "\n",
    "\n",
    "batch_size=32\n",
    "model_path = './2024-01-20_19_19_14_707076.pth'\n",
    "test_dataset = TrapDataset(cdr_dir= './cdr_feat', epi_dir= './epi_feat', data_dirs='test.csv',\n",
    "                        graph_ls_file='test.bin',\n",
    "                        graph_dic_path='test', path_marker='/',\n",
    "                        del_tmp_files=True, p_max=epi_max, b_max=b_max)\n",
    "\n",
    "test_dataloader = DataLoaderX(test_dataset, batch_size, shuffle=False, num_workers=0,\n",
    "                                      collate_fn=collate_fn_v2)\n",
    "\n",
    "TRAP_Model = TransTRAP(p_max=epi_max, b_max=b_max, in_feat_b=1280, in_feat_p=1470, batch_size=batch_size)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAP_Model.to(device)\n",
    "TRAP_Model.load_state_dict(torch.load(model_path,\n",
    "                                    map_location = device)['model_state_dict'])\n",
    "\n",
    "TRAP_Model.eval()\n",
    "pred = []\n",
    "key = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i_batch, batch in enumerate(test_dataloader):\n",
    "            bgb, bgp, y, key_ = batch\n",
    "            bgb, bgp, y = bgb.to(device), bgp.to(device), y.to(device)\n",
    "            pred_, _= TRAP_Model(bgb, bgp)\n",
    "            pred.extend(pred_.squeeze().data.cpu().numpy())\n",
    "            key.extend(key_)\n",
    "\n",
    "pd_te = pd.DataFrame({'key': key, 'test_pred': pred})\n",
    "pd_te.to_csv('prediction.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
